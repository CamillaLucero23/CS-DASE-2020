View(infoForPairs)
View(delayedFlightsData)
#filter out all flights that had departure delays of 12 or more hours
#and arrival delays of 18 hours or more
delayedFlightsData = filter(flightsDataSet, dep_delay >= 12 | arr_delay >= 18)
install.packages("nycflights13")
install.packages("nycflights13")
library(dplyr)
flightsDataSet = nycflights13::flights
View(flightsDataSet)
#filter out all flights that had departure delays of 12 or more hours
#and arrival delays of 18 hours or more
delayedFlightsData = filter(flightsDataSet, dep_delay >= 12 | arr_delay >= 18)
#filter out all flights that departed in the Summer (July, Aug, Sept) that are operated
#by JetBlue ("B6") that flew from JFK to MIA or BQN
jetBlueFlightsData = filter(flightsDataSet, month >= 7 | month <=9 & carrier == "B6"
& origin == "JFK" & dest == "MIA" | dest == "BQN" )
View(jetBlueFlightsData)
#filter out all flights that departed in the Summer (July, Aug, Sept) that are operated
#by JetBlue ("B6") that flew from JFK to MIA or BQN
jetBlueFlightsData = filter(flightsDataSet, month >= 7 | month <=9 ) # Get month
View(jetBlueFlightsData)
#filter out all flights that departed in the Summer (July, Aug, Sept) that are operated
#by JetBlue ("B6") that flew from JFK to MIA or BQN
jetBlueFlightsData = filter(flightsDataSet, 7 <= month & month <=9 ) # Get month
View(jetBlueFlightsData)
jetBlueFlightsData = filter(jetBlueFlightsData, carrier == "B6")
View(jetBlueFlightsData)
jetBlueFlightsData = filter(jetBlueFlightsData, origin == "JFK" & dest == "MIA"
| dest == "BQN") #get origin & destination
View(flightsDataSet)
#write a script, using select() function, to select subset of data that
#include all columns but the following:  distance, hour, minute, time_hour
excludedColumnsData = select(flightsDataSet, !c(distance, hour, minute, time_hour))
View(flightsDataSet)
View(flightsDataSet)
#write a script, using mutate() function, to add a new column representing flight
#operation costs. In here, the cost of operation for each flight is considered as
#the sum of air-time cost ($5 per hour of air time) and fly distance cost
#($3 per mile traveled)
flightDataAddOperationCost = mutate(flightsDataSet,
flight_operation = (5 * air_time) + (3 * distance))
View(flightDataAddOperationCost)
#write a script, using mutate() function, to add a new column representing flight
#operation costs. In here, the cost of operation for each flight is considered as
#the sum of air-time cost ($5 per hour of air time) and fly distance cost
#($3 per mile traveled)
flightDataAddOperationCost = mutate(flightsDataSet,
oper_cost = (5 * air_time) + (3 * distance))
View(flightDataAddOperationCost)
#write a script that calculates the correlation between every numerical
#column in flights dataset.
numericalFlightData = select(flightDataSet, !c(carrier, tailnum, origin, dest, time_hour))
#write a script that calculates the correlation between every numerical
#column in flights dataset.
numericalFlightData = select(flightsDataSet, !c(carrier, tailnum, origin, dest, time_hour))
#omit non-numerical data...
numericalFlightData = na.omit(numericalFlightData)
View(numericalFlightData)
numericalFlightData = cor(x = numericalFlightData)
View(numericalFlightData)
flightDataCorrelations = cor(x = numericalFlightData, )# Create Correlations
, Sept) that are operated
#write a script that calculates the correlation between every numerical
#column in flights dataset.
numericalFlightData = select(flightsDataSet, !c(carrier, tailnum, origin, dest, time_hour))
#omit non-numerical data...
numericalFlightData = na.omit(numericalFlightData)# omit NA's
flightDataCorrelations = cor(x = numericalFlightData, )# Create Correlations
source("C:/Classes/2023-2024/CS 2020/Homework/CS-DASE-2020/midterm_camilla_lucero.R")
source("C:/Classes/2023-2024/CS 2020/Homework/CS-DASE-2020/midterm_camilla_lucero.R")
view(flightDataCorrelations)
#In each normal distribution below, mean is 1150 and standard deviation 105, find the indicated value of x
#Graph 1 A = 0.6
graph1X = pnorm(0.6,mean=1150, sd=105)
#In each normal distribution below, mean is 1150 and standard deviation 105, find the indicated value of x
#Graph 1 A = 0.6
graph1X = pnorm(x,mean=1150, sd=105)
#In each normal distribution below, mean is 1150 and standard deviation 105, find the indicated value of x
#Graph 1 A = 0.6
graph1X = pnorm(x,mean=1150, sd=105)
#In each normal distribution below, mean is 1150 and standard deviation 105, find the indicated value of x
#Graph 1 A = 0.6
graph1X = dnorm(0.6,mean=1150, sd=105)
print(graph1X)
#In each normal distribution below, mean is 1150 and standard deviation 105, find the indicated value of x
#Graph 1 A = 0.6
graph1X = pnorm(area=0.6,mean=1150, sd=105)
#In each normal distribution below, mean is 1150 and standard deviation 105, find the indicated value of x
#Graph 1 A = 0.6
graph1X = qnorm(0.6,mean=1150, sd=105)
print(graph1X)
#Graph 2, A = 0.8
graph2X = qnorm(0.8, mean, stdev)
print(graph2X)
#In each normal distribution below, mean is 1150 and standard deviation 105,
#find the indicated value of x
mean = 1150
stdev = 105
#Graph 2, A = 0.8
graph2X = qnorm(0.8, mean, stdev)
print(graph2X)
#Graph 2, A = 0.8
graph2X = qbinorm(0.8, mean, stdev)
#Graph 2, A = 0.8
graph2X = qbinom(0.8, mean, stdev)
#Graph 2, A = 0.8
graph2X = qnorm(0.8, mean, stdev)
print(graph2X)
#Graph 2, A = 0.8
graph2X = qnorm(0.8, mean, stdev,lower.tail = FALSE)
#Graph 1 A = 0.6
graph1X = qnorm(0.6,mean,stdev)
print(graph1X)
#Graph 2, A = 0.8
graph2X = qnorm(0.8, mean, stdev,lower.tail = FALSE)
print(graph2X)
#Graph 3, A = 0.95
graph3X = qnorm(0.95, mean, stdev,lower.tail= FALSE)
print(graph3X) # =
#Graph 4, A = 0.99
graph4x = qnorm(0.99, mean, stdev)
print(graph4x) # =
flightDataCorrelations = cor(x = numericalFlightData, )# Create Correlations
view(flightDataCorrelations)
plot(flightDataCorrelations)
corrplot(flightDataCorrelations)
corplot(flightDataCorrelations)
View(flightDataCorrelations)
View(flightDataCorrelations)
#Graph 1 A = 0.6
question2_1X = qnorm(0.6,mean,stdev)
print(question2_1X) # = 1176.601
#Graph 2, A = 0.8
question2_2x = qnorm(0.8, mean, stdev,lower.tail = FALSE)
print(question2_2x) # = 1061.63
#Graph 3, A = 0.95
question2_3X = qnorm(0.95, mean, stdev,lower.tail= FALSE)
print(question2_3x) # = 997.2904
#Graph 4, A = 0.99
question2_4x = qnorm(0.99, mean, stdev)
print(question2_4x) # = 1394.297
#------------------------------------------------------------------------------------
#Q3
#Find the shaded area in the following with the assumption that sample mean is 105
#and standard deviation is 10.
mean = 105
stdev = 10
#Graph 1, shaded = 120
question3_1sh = pnorm(120,mean, stdev)
#Graph 3, A = 0.95
question2_3X = qnorm(0.95, mean, stdev,lower.tail= FALSE)
print(question3_1sh)
#Graph 3, shaded = between 90 and 115
upperBoundShaded = pnorm(115,mean, stdev)
lowerBoundShaded = pnorm(90,mean, stdev)
question3_3sh = upperBoundShaded - lowerBoundShaded
print(question3_3sh)
#Graph 4, shaded = between 75 and 110
upperBoundShaded = pnorm(75,mean, stdev)
lowerBoundShaded = pnorm(110,mean, stdev)
question3_4sh = upperBoundShaded - lowerBoundShaded
print(question3_4sh)
#Graph 4, shaded = between 75 and 110
upperBoundShaded = pnorm(110,mean, stdev)
lowerBoundShaded = pnorm(75,mean, stdev)
question3_4sh = upperBoundShaded - lowerBoundShaded
print(question3_4sh)
#Graph 2, shaded = 80
question3_2sh = pnorm(80,mean, stdev, lower.tail = FALSE)
print(question3_2sh) =
#Graph 3, shaded = between 90 and 115
upperBoundShaded = pnorm(115,mean, stdev)
print(question3_2sh)#=
source("C:/Classes/2023-2024/CS 2020/Homework/CS-DASE-2020/midterm_camilla_lucero.R")
#filter out all flights that had departure delays of 12 or more hours
#and arrival delays of 18 hours or more
delayedFlightsData = filter(flightsDataSet, dep_delay >= 12 & arr_delay >= 18)
view(delayedFlightsData)#results
View(flightsDataSet)
View(delayedFlightsData)#results
source("C:/Classes/2023-2024/CS 2020/Homework/CS-DASE-2020/midterm_camilla_lucero.R")
flightDataCorrelations = cor(numericalFlightData)# Create Correlations
#Graph 3, A = 0.95
question2_3X = qnorm(0.95, mean, stdev,lower.tail= FALSE)
print(question2_3X) # = 997.2904
flightDataCorrelations = cor(numericalFlightData)# Create Correlations
View(flightDataCorrelations)
source("C:/Classes/2023-2024/CS 2020/Homework/CS-DASE-2020/midterm_camilla_lucero.R")
source("C:/Classes/2023-2024/CS 2020/Homework/CS-DASE-2020/midterm_camilla_lucero.R")
source("C:/Classes/2023-2024/CS 2020/Homework/CS-DASE-2020/midterm_camilla_lucero.R")
gc()
#D. Degrees of Freedom...
genders = 2 #we will only use 2 genders for this
numOptions = 5 #the number of possible options for participants to choose from
df = (numOptions - 1) * (genders - 1)
#E. Find critical values at Œ± =.01 and Œ± = .05.
value1 = .01
value2 = .05
critVal1 = qchisq(1 - value1, df)
critVal2 = qchisq(1 - value2, df)
#----------------------------------------------------------------------------------------------
#Q2. Find the critical value for ùúí2 test with 5 degrees of freedom and significance level of
#Œ± = .15
df = 5
value3 = .15
critVal3 = qchisq(1 - value3, df)
library(readxl)
CSDASE_202_HW_03_data_set <- read_excel("~/CSDASE 202 HW 03 data set.xlsx",
col_types = c("text", "numeric", "numeric",
"numeric"))
View(CSDASE_202_HW_03_data_set)
#----------------------------------------------------------------------------------------------
#Q3. Assume you have following information about voting population in a small city with
#their breakdown on gender and party.
genderVPartyData = CSDASE_202_HW_03_data_set
#----------------------------------------------------------------------------------------------
#Q3. Assume you have following information about voting population in a small city with
#their breakdown on gender and party.
data() <- matrix(c(4084, 2391, 2433, 7062, 3207, 1468), nrow = 2, byrow = TRUE)
#----------------------------------------------------------------------------------------------
#Q3. Assume you have following information about voting population in a small city with
#their breakdown on gender and party.
data() <- matrix(c(4084, 2391, 2433, 7062, 3207, 1468), nrow = 2)
rownames(data) <- c("F", "M")
colnames(data) <- c("Democrat", "Independent", "Republican")
#----------------------------------------------------------------------------------------------
#Q3. Assume you have following information about voting population in a small city with
#their breakdown on gender and party.
data() <- matrix(c(4084, 2391, 2433, 7062, 3207, 1468), nrow = 2, ncol = 3, )
#----------------------------------------------------------------------------------------------
#Q3. Assume you have following information about voting population in a small city with
#their breakdown on gender and party.
data() <- matrix(c(4084, 2391, 2433, 7062, 3207, 1468), nrow = 2, ncol = 3)
#----------------------------------------------------------------------------------------------
#Q3. Assume you have following information about voting population in a small city with
#their breakdown on gender and party.
data = matrix(c(4084, 2391, 2433, 7062, 3207, 1468), nrow = 2, ncol = 3)
rownames(data) = c("F", "M")
colnames(data) = c("Democrat", "Independent", "Republican")
View(data)
#----------------------------------------------------------------------------------------------
#Q3. Assume you have following information about voting population in a small city with
#their breakdown on gender and party.
data = matrix(c(4084, 2391, 2433, 7062, 3207, 1468), nrow = 2, ncol = 4)
rownames(data) = c("F", "M")
colnames(data) = c("Gender","Democrat", "Independent", "Republican")
colnames(data) = c("Democrat", "Independent", "Republican")
#----------------------------------------------------------------------------------------------
#Q3. Assume you have following information about voting population in a small city with
#their breakdown on gender and party.
data = matrix(c(4084, 2391, 2433, 7062, 3207, 1468), nrow = 2, ncol = 3)
rownames(data) = c("F", "M")
colnames(data) = c("Democrat", "Independent", "Republican")
data = matrix(c(4084, 7062, 2391, 3207, 2433, 1468), nrow = 2, ncol = 3)
rownames(data) = c("F", "M")
colnames(data) = c("Democrat", "Independent", "Republican")
source("C:/Classes/2023-2024/CS 2020/Homework/CS-DASE-2020/hw03_camilla_lucero.R")
source("C:/Classes/2023-2024/CS 2020/Homework/CS-DASE-2020/hw03_camilla_lucero.R")
x2stat = chisq.test(data)
View(x2stat)
View(x2stat)
print (x2stat.statistic)
print (x2stat$statistic) #statistic
print (x2stat$parameter$df)
print (x2stat$parameter
print (x2stat$parameter)
print (x2stat$parameter$df)
print (x2stat$parameter.parameter)
print (x2stat$parameter.parameter$df)
print (x2stat$parameter$df)
print (x2stat$parameter)
print (x2stat$p.value) #p.value =
x2stat = chisq.test(data)
View(x2stat)
print (x2stat$statistic) #statistic = 780.317
print (x2stat$parameter) #df = 2
print (x2stat$p.value) #p.value =  5.600e-170
source("C:/Classes/2023-2024/CS 2020/Homework/CS-DASE-2020/hw03_camilla_lucero.R")
View(x2stat)
source("C:/Classes/2023-2024/CS 2020/Homework/CS-DASE-2020/hw03_camilla_lucero.R")
gc()
source("C:/Classes/2023-2024/CS 2020/Homework/CS-DASE-2020/hw03_camilla_lucero.R")
#c)
#Intialize Drink_sugar
Drink_sugar= c(9.976959, 10.012098, 9.963002, 9.998574, 10.002431, 10.036959,
10.014752, 9.985491, 10.026681, 9.981070, 10.011058, 9.958206,
10.047110, 9.931327, 9.980533, 9.982266, 9.956010, 9.992339,
9.957293, 9.907988, 9.983450, 10.018341, 9.979281, 9.931443,
10.019777)
correctSugarAmmount = 10
oneSampleTestDrink =t.test(Drink_sugar,correctSugarAmmount)
oneSampleTestDrink =t.test(Drink_sugar,mu = correctSugarAmmount)
View(oneSampleTestDrink)
#report results...
print(oneSampleTestDrink$statistic) # statistic = -2
print(oneSampleTestDrink$p.value)
print("p value: " + oneSampleTestDrink$p.value) #p.value =
print("p value: ", oneSampleTestDrink$p.value) #p.value =
print(oneSampleTestDrink$parameter)
#c)
#Intialize Drink_sugar
Drink_sugar = c(9.976959, 10.012098, 9.963002, 9.998574, 10.002431, 10.036959,
10.014752, 9.985491, 10.026681, 9.981070, 10.011058, 9.958206,
10.047110, 9.931327, 9.980533, 9.982266, 9.956010, 9.992339,
9.957293, 9.907988, 9.983450, 10.018341, 9.979281, 9.931443,
10.019777)
#Initialize the intented sugar amount
correctSugarAmount = 10
#Conduct one-sample t-test where Drink_sugar is the data set from 25 made drinks and
#mu, or our mean value to be compared to, is the correct sugar amount of 10
oneSampleTestDrink =t.test(Drink_sugar,mu = correctSugarAmount)
#report results...
print(oneSampleTestDrink$statistic) # statistic = -2.021437
print(oneSampleTestDrink$p.value) #p.value = 0.05452193
print(oneSampleTestDrink$parameter) #df = 24
#initialize the data from before and after...
Daily_Sale_Before_Discount_Program = c (49971.98, 49988.49, 50077.94, 50003.53, 50006.46, 50085.75, 50023.05)
Daily_Sale_After_Discount_Program = c(50011.75, 50040.66, 50052.72, 50136.20, 50092.99, 50095.04, 50080.53)
pairedSampleTestDiscounts = t.test(Daily_Sale_Before_Discount_Program,Daily_Sale_After_Discount_Program)
#Do the test with our data samples
pairedSampleTestDiscounts = t.test(Daily_Sale_Before_Discount_Program,Daily_Sale_After_Discount_Program, paired = TRUE)
print(pairedSampleTestDiscounts)
#report results...
print(oneSampleTestDrink)
View(pairedSampleTestDiscounts)
#----------------------------------------------------------------------------------------------
#Q3. Assume you have following information about voting population in a small city with
#their breakdown on gender and party.
data = matrix(c(4084, 7062, 2391, 3207, 2433, 1468), nrow = 2, ncol = 3)
rownames(data) = c("F", "M")
colnames(data) = c("Democrat", "Independent", "Republican")
#A. Null Hypoth. (H0) - there is no significant association between gender and political affiliation,
#   Alt. Hypoth. (H1) - There is a significant association between gender and politcal affliation.
#B. Return the results of chi-square test in a variable X2stat and prints X-square statistics,
#   df, and p value
x2stat = chisq.test(data)
View(x2stat)
print (x2stat$statistic) #statistic = 780.317
print (x2stat$parameter) #df = 2
print (x2stat$p.value) #p.value =  3.600e-170
x2stat = chisq.test(Mmm)
#C. Explain what does ‚Äúobserved‚Äù, ‚Äúexpected‚Äù, ‚Äúresiduals‚Äù, and ‚Äústdres‚Äù fields in
#   X2stat represent
print(x2stat$observed)
print(x2stat$expected)
print(x2stat$residuals)
print(x2stat$stdres)
print(x2stat)
source("C:/Classes/2023-2024/CS 2020/Homework/CS-DASE-2020/final_camilla_lucero.R")
load("C:/Classes/2023-2024/CS 2020/Homework/CS-DASE-2020/MechanicSalary.RData")
View(MData.Salary)
# Load the dataset
load("MechanicSalary.RData")
# Check the structure of the data
str(mechanic_data)
#Q1
# Load the dataset
mechanicData = MData.Salary
# Linear regression
mechanicLinearRegModel <- lm(formula= salary ~ sex + Specialization + yrs.with.license + yrs.working + License.type, data = mechanic_data)
# Load the dataset
mechanicData = MData.Salary
# Linear regression
mechanicLinearRegModel <- lm(formula= salary ~ sex + Specialization + yrs.with.license + yrs.working + License.type, data = mechanicData)
# Linear regression
mechanicLinearRegModel <- lm(formula= salary ~ sex + Specialization + yrs.with.license + yrs.working + Licence.type, data = mechanicData)
# Summary of the regression
summary(mechanicLinearRegModel)
source("C:/Classes/2023-2024/CS 2020/Homework/CS-DASE-2020/final_camilla_lucero.R")
# Hypothesis testing for pairwise correlations
cor_test_result <- cor.test(mechanicData$Salary, mechanicData$Specialization, method = "pearson")
# Hypothesis testing for pairwise correlations
mechanicCorTestResult <- cor.test(x = mechanicData$Salary, y = mechanicData$Specialization, method = "pearson")
# Hypothesis testing for pairwise correlations
mechanicCorTestResult <- cor.test(x = mechanicData$salary, y = mechanicData$Specialization, method = "pearson")
# Hypothesis testing for pairwise correlations
mechanicCorTestResult <- cor.test(x = mechanicData$salary, y = c(mechanicData$Specialization), method = "pearson")
# Hypothesis testing for pairwise correlations
mechanicCorTestResult <- cor.test(x = mechanicData$salary, y = mechanicData$Licence.type, method = "pearson")
# Hypothesis testing for pairwise correlations
mechanicCorTestResult <- cor.test(x = mechanicData$salary, y = mechanicData$yrs.with.license, method = "pearson")
print(cor_test_result)
print(mechanicCor_yrswlicense)
# Hypothesis testing for pairwise correlations
#check for corelations between salary & license years
mechanicCor_yrswlicense = cor.test(x = mechanicData$salary, y = mechanicData$yrs.with.license, method = "pearson")
print(mechanicCor_yrswlicense)
mechanicCor_yrsworking = cor.test(mechanicData$salary, mechanicData$yrs.working, method= "pearson")
print(mechanicCor_yrsworking)
# Hypothesis testing for pairwise correlations
library(lsr)
# Hypothesis testing for pairwise correlations
correlate(mechanicData, test=TRUE)
# Hypothesis testing for pairwise correlations
install.packages("lsr")
correlate(mechanicData, test=TRUE)
correlate(mechanicData, test=TRUE)
correlation(mechanicData, test=TRUE)
correlate(mechanicData, test=TRUE)
# Hypothesis testing for pairwise correlations
install.packages("lsr")
correlate(mechanicData, test=TRUE)
correlate(mechanicData)
library(lsr)
correlate(mechanicData)
correlate(mechanicData, test=TRUE)
View(mechanicLinearRegModel)
# Load the dataset
mechanicData = MData.Salary
load("C:/Classes/2023-2024/CS 2020/Homework/CS-DASE-2020/MechanicSalary.RData")
# Load the dataset
mechanicData = MData.Salary
# Linear regression
mechanicLinearRegModel = lm(formula= salary ~ sex + Specialization + yrs.with.license + yrs.working + Licence.type, data = mechanicData)
# Summary of the regression
summary(mechanicLinearRegModel)
# Hypothesis testing for pairwise correlations
install.packages("lsr") #install just in case
install.packages("lsr")
library(lsr)
#correlate & print
correlate(mechanicData, test=TRUE)
# Load the dataset
df = read.csv("Alzheimer.csv")
Alzheimer <- read.csv("C:/Classes/2023-2024/CS 2020/Homework/CS-DASE-2020/CSV files/Alzheimer.csv")
View(Alzheimer)
# a.1) Relationship between drug administered and participants' gender
table_a1 <- table(alzheimerData$DrugType, alzheimerData$Gender)
# Load the necessary library
library(tidyr)
library(dplyr)
library(stats)
# Load the dataset
alzheimerData = Alzheimer
# a.1) Relationship between drug administered and participants' gender
table_a1 <- table(alzheimerData$DrugType, alzheimerData$Gender)
print("Cross-tabulation of Drug Type and Gender:\n", table_a1)
print(tablea1)
# a.1) Relationship between drug administered and participants' gender
tablea1 <- table(alzheimerData$DrugType, alzheimerData$Gender)
print(tablea1)
gc()
# a.2) Relationship between drug administered and drug's effectiveness scale
drugeffectivenessa2 <- alzheimerData %>% group_by(DrugType) %>% summarise(mean_effectiveness = mean(EffectivenessScale))
print(drugeffectivenessa2)
# b.1) Two-way ANOVA for the type of drug administered and participants' genders on drug effectiveness scale
modelb1 <- aov(EffectivenessScale ~ DrugType * Gender, data=alzheimerData)
summary(modelb1)
# b.2) Two-way ANOVA for the combined effect of the drug administered and participants' genders on drug effectiveness scale
modelb2 <- aov(EffectivenessScale ~ DrugType + Gender + DrugType:Gender, data=alzheimerData)
summary(modelb2)
# a.1) Relationship between drug administered and participants' gender
alzCor_a1 <- correlate(alzheimerData$DrugType, alzheimerData$Gender)
source("C:/Classes/2023-2024/CS 2020/Homework/CS-DASE-2020/final_camilla_lucero.R")
install.packages("lsr")
x = mechanicLinearRegModel$residuals
y = mechanicData$salary
plot(x, y, main= "Salary vs Residuals", ylab= "Salary", xlab= "Residuals")
abline = (mechanicLinearRegModel, col= "red")
abline = (h=mechanicLinearRegModel,col= "red")
abline(mechanicLinearRegModel, col = 'red')
View(mechanicData)
View(mechanicData)
#Fix character values
genderMap = c("Male" = 1, "Female" = 2)
mechanicData$sex = match(mechanicData$sex, names(genderMap))
licenseMap = c("A" = 1, "B" = 2)
mechanicData$Licence.type = match(mechanicData$Licence.type, names(licenseMap))
specMap = c("Electronics" = 1, "Engine" = 2, "Body" = 3)
mechanicData$Specialization = match(mechanicData$Specialization, names(specMap))
#correlate & print
correlate(mechanicData, test=TRUE)
# Load the necessary library
library(tidyr)
# Hypothesis testing for pairwise correlations
install.packages("lsr") #install just in case
library(lsr)
#correlate & print
correlate(mechanicData, test=TRUE)
# Load the necessary library
library(tidyr)
library(dplyr)
library(stats)
# Load the dataset
alzheimerData = Alzheimer
#Fix variables
medicineMap = c('A' = 1, 'B' = 2, 'C' = 3)
genderMap = c('m' = 1, 'f' = 2)
alzheimerData$DrugType= match(alzheimerData$DrugType, names(medicineMap))
alzheimerData$Gender= match(alzheimerData$Gender, names(genderMap))
# a.1) Relationship between drug administered and participants' gender
oneWayAnova = aov(alzheimerData$Gender ~ alzheimerData$DrugType)
summary(oneWayAnova)
# a.2) Relationship between drug administered and drug's effectiveness scale
drugVsEffect = aov(alzheimerData$DrugType ~ alzheimerData$EffectivenessScale)
summary(drugVsEffect)
# a.3) Relationship between participants' gender and drug's effectiveness scale
genderVsEffect = aov(alzheimerData$Gender ~ alzheimerData$EffectivenessScale)
summary(genderVsEffect)
# b.1) Two-way ANOVA for the type of drug administered and participants' genders on drug effectiveness scale
modelb1 <- aov(EffectivenessScale ~ DrugType + Gender, data=alzheimerData)
summary(modelb1)
# b.2) Two-way ANOVA for the combined effect of the drug administered and participants' genders on drug effectiveness scale
modelb2 <- aov(EffectivenessScale ~ DrugType * Gender, data=alzheimerData)
summary(modelb2)
# Summary of the regression & Plot
summary(mechanicLinearRegModel)
View(mechanicLinearRegModel)
View(mechanicLinearRegModel)
source("C:/Classes/2023-2024/CS 2020/Homework/CS-DASE-2020/final_camilla_lucero.R")
install.packages("lsr")
